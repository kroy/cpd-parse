{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21365/4140774523.py:7: DtypeWarning: Columns (1,4,15,16,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uof_df = pd.read_csv(base_file_path + \"/events/uof_full.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data_tweak.normalizers import normalize_race, normalize_sex\n",
    "\n",
    "base_file_path = \"../files\"\n",
    "\n",
    "officer_prof_df = pd.read_csv(base_file_path + \"/profiles/officers_index.csv\")\n",
    "uof_df = pd.read_csv(base_file_path + \"/events/uof_full.csv\")\n",
    "\n",
    "uof_df[\"off_sex\"] = uof_df[\"off_sex\"].transform(normalize_sex)\n",
    "uof_df[\"off_race\"] = uof_df[\"off_race\"].transform(normalize_race)\n",
    "officer_prof_df[\"off_sex\"] = officer_prof_df[\"off_sex\"].transform(normalize_sex)\n",
    "officer_prof_df[\"off_race\"] = officer_prof_df[\"off_race\"].transform(normalize_race)\n",
    "\n",
    "join_left_cols = [\"off_first_name\", \"off_last_name\", \"off_birth_year\", \"off_sex\", \"off_race\"]\n",
    "join_right_cols = [\"off_first_name\", \"off_last_name\", \"off_year_of_birth\", \"off_sex\", \"off_race\"]\n",
    "\"\"\" write a file containing uof events missing pieces of our join key \"\"\"\n",
    "uof_df[uof_df[join_left_cols].isna().any(axis=1)].to_csv(base_file_path + \"/events/officer_id_merged/excluded/uof_keys_missing_filter_1.csv\", index=False)\n",
    "officer_prof_df[officer_prof_df[join_right_cols].isna().any(axis=1)].to_csv(base_file_path + \"/events/officer_id_merged/excluded/officer_profs_keys_missing_filter_1.csv\", index=False)\n",
    "\"\"\" drop rows in our data sets for which some piece of the join key is null/nonexistent \"\"\"\n",
    "uof_df.dropna(axis=\"index\", how=\"any\", subset=join_left_cols, inplace=True)\n",
    "officer_prof_df.dropna(axis=\"index\", how=\"any\", subset=join_right_cols, inplace=True)\n",
    "\n",
    "\"\"\" merge our data \"\"\"\n",
    "uof_merged_df = pd.merge(uof_df, officer_prof_df, how=\"left\", left_on=join_left_cols, right_on=join_right_cols, validate=\"m:m\")\n",
    "\n",
    "\"\"\" find uof incidents we've matched to more than one officer \"\"\"\n",
    "matches_by_uof_id = uof_merged_df.groupby(\"uof_id\").size().reset_index(name=\"count\")\n",
    "uof_ids_multiple_matches = matches_by_uof_id[matches_by_uof_id[\"count\"] > 1][\"uof_id\"].to_numpy()\n",
    "row_mask = uof_merged_df.isin({'uof_id': uof_ids_multiple_matches}).any(1)\n",
    "\"\"\" uof incidents matched to more than one officer \"\"\"\n",
    "uof_merged_df[row_mask].to_csv(base_file_path + \"/events/officer_id_merged/uof_merged_double_match_filter_1.csv\", index=False)\n",
    "\"\"\" write a file containing uof incidents we could not match to an officer \"\"\"\n",
    "uof_merged_df[uof_merged_df[\"off_uniq_id\"].isna()].to_csv(base_file_path + \"/events/officer_id_merged/uof_merged_no_match_filter_1.csv\", index=False)\n",
    "\"\"\" write a file containing uof incidents merged with officer info \"\"\"\n",
    "uof_merged_df.to_csv(base_file_path + \"/events/officer_id_merged/uof_merged_filter_1.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
