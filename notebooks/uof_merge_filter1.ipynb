{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/479387818.py:7: DtypeWarning: Columns (1,4,15,16,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_uof_df = pd.read_csv(\"../files/events/uof_full.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UoF records 91955\n",
      "number of missing first/last names 10477\n",
      "merging on [off_first_name, off_last_name, off_middle_initial, off_sex, off_race, off_birth_year]\n",
      "Based on the join key [off_first_name, off_last_name, off_middle_initial, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of matches: 65956\n",
      "Based on the join key [off_first_name, off_last_name, off_middle_initial, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of unmatched records: 15561\n",
      "Based on the join key [off_first_name, off_last_name, off_middle_initial, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of records with more than one match: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/479387818.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uof_df.loc[:, \"off_original_last_name\"] = uof_df.loc[:, \"off_last_name\"]\n",
      "/tmp/ipykernel_4265/479387818.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uof_df.loc[:, \"off_last_name\"] = np.where(uof_df[\"off_suffix\"].notna(), uof_df[\"off_last_name\"] + \" \" + uof_df[\"off_suffix\"], uof_df[\"off_last_name\"])\n",
      "/tmp/ipykernel_4265/479387818.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  successfully_merged.loc[:,\"notes\"] = \"merged on [\" + \", \".join(join_key_1) + \"] with off_suffix appended\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_tweak.converters import convert_race, convert_sex\n",
    "from metrics.analyze_df import matches, unmatched, dupes\n",
    "\n",
    "out_file_path = \"../files/events/officer_id_merged/uof/filter_1\"\n",
    "original_uof_df = pd.read_csv(\"../files/events/uof_full.csv\")\n",
    "original_cols = list(original_uof_df.columns.to_list())\n",
    "out_cols = original_cols + [\"off_uniq_id\", \"off_original_last_name\", \"notes\"]\n",
    "profs_df = pd.read_csv(\"../files/profiles/officer_roster.csv\")\n",
    "\n",
    "convert_race(original_uof_df, [\"off_race\", \"civ_race\"])\n",
    "convert_sex(original_uof_df, [\"off_sex\", \"civ_sex\"])\n",
    "\n",
    "profs_df = profs_df.rename(columns={\"off_year_of_birth\": \"off_birth_year\"})\n",
    "\n",
    "missing_names = original_uof_df[original_uof_df[[\"off_first_name\", \"off_last_name\"]].isna().all(axis=1)]\n",
    "missing_names.to_csv(out_file_path + \"/missing_names.csv\")\n",
    "\n",
    "print(\"Number of UoF records\", original_uof_df.shape[0])\n",
    "print(\"number of missing first/last names\", missing_names.shape[0])\n",
    "\n",
    "\"\"\" merge these using the assignments file \"\"\"\n",
    "uof_df = original_uof_df.dropna(subset=[\"off_first_name\", \"off_last_name\"], how=\"all\")\n",
    "\n",
    "\"\"\" combine suffixes if they exist \"\"\"\n",
    "uof_df.loc[:, \"off_original_last_name\"] = uof_df.loc[:, \"off_last_name\"]\n",
    "uof_df.loc[:, \"off_last_name\"] = np.where(uof_df[\"off_suffix\"].notna(), uof_df[\"off_last_name\"] + \" \" + uof_df[\"off_suffix\"], uof_df[\"off_last_name\"])\n",
    "\n",
    "join_key_1 = [\"off_first_name\", \"off_last_name\", \"off_middle_initial\", \"off_sex\", \"off_race\", \"off_birth_year\"]\n",
    "\n",
    "print(\"merging on [\" + \", \".join(join_key_1) + \"]\")\n",
    "merged_df = pd.merge(uof_df, profs_df, on=join_key_1, how=\"left\", suffixes=(\"\", \"_prof\"))\n",
    "successfully_merged = matches(merged_df, \"off_uniq_id\", merged_on=join_key_1)\n",
    "successfully_merged.loc[:,\"notes\"] = \"merged on [\" + \", \".join(join_key_1) + \"] with off_suffix appended\"\n",
    "\n",
    "unjoined = unmatched(merged_df, \"off_uniq_id\", merged_on=join_key_1).loc[:, uof_df.columns]\n",
    "# unjoined.to_csv(out_file_path + \"/unjoined.csv\")\n",
    "\n",
    "multi_matches = dupes(successfully_merged, \"uof_id\", merged_on=join_key_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/1251971575.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_merge_successes[\"notes\"] = \"merged on [\" + \", \".join(join_key_2) + \"] with off_suffix appended\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the join key [off_first_name, off_last_name, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of matches: 14358\n",
      "Based on the join key []:\n",
      "\tNumber of records with more than one match: 63\n",
      "Based on the join key [off_first_name, off_last_name, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of unmatched records: 1227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_first_name</th>\n",
       "      <th>off_last_name</th>\n",
       "      <th>off_sex</th>\n",
       "      <th>off_race</th>\n",
       "      <th>off_birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RODNEY</td>\n",
       "      <td>JACKSON</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>KENNETH</td>\n",
       "      <td>GALVIN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>MARK</td>\n",
       "      <td>HERNANDEZ</td>\n",
       "      <td>MALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>1974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>HAROLD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>HAROLD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575</th>\n",
       "      <td>JAIME</td>\n",
       "      <td>VELEZ JR</td>\n",
       "      <td>MALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>1965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15578</th>\n",
       "      <td>RAPHAEL</td>\n",
       "      <td>MITCHEM</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15581</th>\n",
       "      <td>CARLOS</td>\n",
       "      <td>RAMOS JR</td>\n",
       "      <td>MALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>1975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15582</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>JACKSON JR</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15583</th>\n",
       "      <td>RONALD</td>\n",
       "      <td>JACKSON JR</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      off_first_name off_last_name off_sex  off_race  off_birth_year\n",
       "38            RODNEY       JACKSON    MALE     BLACK          1964.0\n",
       "145          KENNETH        GALVIN    MALE     BLACK          1960.0\n",
       "204             MARK     HERNANDEZ    MALE  HISPANIC          1974.0\n",
       "528           HAROLD         WHITE    MALE       NaN          1988.0\n",
       "584           HAROLD         WHITE    MALE       NaN          1988.0\n",
       "...              ...           ...     ...       ...             ...\n",
       "15575          JAIME      VELEZ JR    MALE  HISPANIC          1965.0\n",
       "15578        RAPHAEL       MITCHEM    MALE     BLACK          1962.0\n",
       "15581         CARLOS      RAMOS JR    MALE  HISPANIC          1975.0\n",
       "15582         RONALD    JACKSON JR    MALE     BLACK          1984.0\n",
       "15583         RONALD    JACKSON JR    MALE     BLACK          1984.0\n",
       "\n",
       "[1227 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_key_2 = [\"off_first_name\", \"off_last_name\", \"off_sex\", \"off_race\", \"off_birth_year\"]\n",
    "second_merge_df = pd.merge(unjoined, profs_df, on=join_key_2, how=\"left\", suffixes=(\"\", \"_prof\"))\n",
    "\n",
    "second_merge_successes = matches(second_merge_df, \"off_uniq_id\", merged_on=join_key_2)\n",
    "second_merge_successes[\"notes\"] = \"merged on [\" + \", \".join(join_key_2) + \"] with off_suffix appended\"\n",
    "successfully_merged = pd.concat([successfully_merged, second_merge_successes])\n",
    "\n",
    "dupes_so_far = dupes(successfully_merged, \"uof_id\")\n",
    "\n",
    "second_merge_unmatched = unmatched(second_merge_df, \"off_uniq_id\", merged_on=join_key_2)\n",
    "second_merge_unmatched.loc[:, join_key_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the join key [off_first_name, off_last_name, off_middle_initial, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of matches: 665\n",
      "Based on the join key [off_first_name, off_last_name, off_middle_initial, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of unmatched records: 562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/602431736.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  second_merge_unmatched.loc[:, \"off_last_name\"] = second_merge_unmatched.loc[:, \"off_original_last_name\"]\n",
      "/tmp/ipykernel_4265/602431736.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  third_merge_matched.loc[:,\"notes\"] = \"merged on [\" + \", \".join(join_key_1) + \"] without off_suffix appended\"\n"
     ]
    }
   ],
   "source": [
    "second_merge_unmatched.loc[:, \"off_last_name\"] = second_merge_unmatched.loc[:, \"off_original_last_name\"]\n",
    "third_merge = pd.merge(second_merge_unmatched.loc[:, uof_df.columns], profs_df, on=join_key_1, how=\"left\", suffixes=(\"\", \"_prof\"))\n",
    "third_merge_matched = matches(third_merge, \"off_uniq_id\", join_key_1)\n",
    "third_merge_matched.loc[:,\"notes\"] = \"merged on [\" + \", \".join(join_key_1) + \"] without off_suffix appended\"\n",
    "third_merge_unmatched = unmatched(third_merge, \"off_uniq_id\", join_key_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the join key [off_first_name, off_last_name, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of matches: 9\n",
      "Based on the join key [off_first_name, off_last_name, off_sex, off_race, off_birth_year]:\n",
      "\tNumber of unmatched records: 553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/579494746.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fourth_merge_matched.loc[:,\"notes\"] = \"merged on [\" + \", \".join(join_key_2) + \"] without off_suffix appended\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uof_id</th>\n",
       "      <th>report_number</th>\n",
       "      <th>date_time</th>\n",
       "      <th>uof_address</th>\n",
       "      <th>subject_cb_no</th>\n",
       "      <th>off_first_name</th>\n",
       "      <th>off_last_name</th>\n",
       "      <th>unit</th>\n",
       "      <th>watch</th>\n",
       "      <th>off_height</th>\n",
       "      <th>...</th>\n",
       "      <th>off_middle_initial_prof</th>\n",
       "      <th>off_appointed</th>\n",
       "      <th>ranks_held</th>\n",
       "      <th>off_star_0</th>\n",
       "      <th>off_star_1</th>\n",
       "      <th>off_star_2</th>\n",
       "      <th>off_star_3</th>\n",
       "      <th>off_star_4</th>\n",
       "      <th>off_star_5</th>\n",
       "      <th>off_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10244</td>\n",
       "      <td>2017-00066</td>\n",
       "      <td>2017-10-20 23:20:00</td>\n",
       "      <td>70XX COTTAGE GROVE AVE</td>\n",
       "      <td>19552937</td>\n",
       "      <td>RODNEY</td>\n",
       "      <td>JACKSON</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10381</td>\n",
       "      <td>2017-00214</td>\n",
       "      <td>2017-11-01 16:04:00</td>\n",
       "      <td>1XX 104TH ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KENNETH</td>\n",
       "      <td>GALVIN</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10462</td>\n",
       "      <td>2017-00328</td>\n",
       "      <td>2017-11-08 12:13:00</td>\n",
       "      <td>11XX GARFIELD BLVD</td>\n",
       "      <td>19560964</td>\n",
       "      <td>MARK</td>\n",
       "      <td>HERNANDEZ</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10860</td>\n",
       "      <td>2017-00784</td>\n",
       "      <td>2017-12-16 16:14:00</td>\n",
       "      <td>63XX COTTAGE GROVE AVE</td>\n",
       "      <td>19577383</td>\n",
       "      <td>HAROLD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10936</td>\n",
       "      <td>2017-00865</td>\n",
       "      <td>2017-12-24 20:25:00</td>\n",
       "      <td>61XX ELLIS AVE</td>\n",
       "      <td>19580777</td>\n",
       "      <td>HAROLD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>507.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>91355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-23 00:15:00</td>\n",
       "      <td>5XX VAN BUREN ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>POLASKI</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>91359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-23 11:05:00</td>\n",
       "      <td>70XX STEWART AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MARK</td>\n",
       "      <td>HERNANDEZ</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>91395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-27 12:38:00</td>\n",
       "      <td>88XX WOOD ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RAPHAEL</td>\n",
       "      <td>MITCHEM</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>91799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-01 20:14:00</td>\n",
       "      <td>26XX 63RD ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RAPHAEL</td>\n",
       "      <td>MITCHEM</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>91858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-05 12:09:00</td>\n",
       "      <td>6XX 131ST ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CARLOS</td>\n",
       "      <td>RAMOS</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uof_id report_number            date_time             uof_address  \\\n",
       "0     10244    2017-00066  2017-10-20 23:20:00  70XX COTTAGE GROVE AVE   \n",
       "1     10381    2017-00214  2017-11-01 16:04:00            1XX 104TH ST   \n",
       "2     10462    2017-00328  2017-11-08 12:13:00      11XX GARFIELD BLVD   \n",
       "3     10860    2017-00784  2017-12-16 16:14:00  63XX COTTAGE GROVE AVE   \n",
       "4     10936    2017-00865  2017-12-24 20:25:00          61XX ELLIS AVE   \n",
       "..      ...           ...                  ...                     ...   \n",
       "557   91355           NaN  2016-02-23 00:15:00        5XX VAN BUREN ST   \n",
       "558   91359           NaN  2016-02-23 11:05:00        70XX STEWART AVE   \n",
       "559   91395           NaN  2016-02-27 12:38:00            88XX WOOD ST   \n",
       "560   91799           NaN  2016-04-01 20:14:00            26XX 63RD ST   \n",
       "561   91858           NaN  2016-04-05 12:09:00            6XX 131ST ST   \n",
       "\n",
       "    subject_cb_no off_first_name off_last_name  unit  watch  off_height  ...  \\\n",
       "0        19552937         RODNEY       JACKSON     3    NaN         NaN  ...   \n",
       "1             NaN        KENNETH        GALVIN   189    NaN       508.0  ...   \n",
       "2        19560964           MARK     HERNANDEZ   189    NaN       511.0  ...   \n",
       "3        19577383         HAROLD         WHITE     3    NaN       508.0  ...   \n",
       "4        19580777         HAROLD         WHITE     3    NaN       507.0  ...   \n",
       "..            ...            ...           ...   ...    ...         ...  ...   \n",
       "557           NaN          JAMES       POLASKI   189    NaN         NaN  ...   \n",
       "558           NaN           MARK     HERNANDEZ     7    NaN         NaN  ...   \n",
       "559           NaN        RAPHAEL       MITCHEM   189    NaN         NaN  ...   \n",
       "560           NaN        RAPHAEL       MITCHEM   189    NaN         NaN  ...   \n",
       "561           NaN         CARLOS         RAMOS     5    NaN         NaN  ...   \n",
       "\n",
       "     off_middle_initial_prof off_appointed ranks_held  off_star_0 off_star_1  \\\n",
       "0                        NaN           NaN        NaN         NaN        NaN   \n",
       "1                        NaN           NaN        NaN         NaN        NaN   \n",
       "2                        NaN           NaN        NaN         NaN        NaN   \n",
       "3                        NaN           NaN        NaN         NaN        NaN   \n",
       "4                        NaN           NaN        NaN         NaN        NaN   \n",
       "..                       ...           ...        ...         ...        ...   \n",
       "557                      NaN           NaN        NaN         NaN        NaN   \n",
       "558                      NaN           NaN        NaN         NaN        NaN   \n",
       "559                      NaN           NaN        NaN         NaN        NaN   \n",
       "560                      NaN           NaN        NaN         NaN        NaN   \n",
       "561                      NaN           NaN        NaN         NaN        NaN   \n",
       "\n",
       "    off_star_2 off_star_3 off_star_4 off_star_5  off_source  \n",
       "0          NaN        NaN        NaN        NaN         NaN  \n",
       "1          NaN        NaN        NaN        NaN         NaN  \n",
       "2          NaN        NaN        NaN        NaN         NaN  \n",
       "3          NaN        NaN        NaN        NaN         NaN  \n",
       "4          NaN        NaN        NaN        NaN         NaN  \n",
       "..         ...        ...        ...        ...         ...  \n",
       "557        NaN        NaN        NaN        NaN         NaN  \n",
       "558        NaN        NaN        NaN        NaN         NaN  \n",
       "559        NaN        NaN        NaN        NaN         NaN  \n",
       "560        NaN        NaN        NaN        NaN         NaN  \n",
       "561        NaN        NaN        NaN        NaN         NaN  \n",
       "\n",
       "[553 rows x 44 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_merge = pd.merge(third_merge_unmatched.loc[:, uof_df.columns], profs_df, on=join_key_2, how=\"left\", suffixes=(\"\", \"_prof\"))\n",
    "fourth_merge_matched = matches(fourth_merge, \"off_uniq_id\", join_key_2)\n",
    "fourth_merge_matched.loc[:,\"notes\"] = \"merged on [\" + \", \".join(join_key_2) + \"] without off_suffix appended\"\n",
    "fourth_merge_unmatched = unmatched(fourth_merge, \"off_uniq_id\", join_key_2)\n",
    "fourth_merge_unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kroy/proj/policing/cpd-parse/notebooks/uof_merge_filter1.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/uof_merge_filter1.ipynb#ch0000004?line=0'>1</a>\u001b[0m left_by \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39moff_assigned_beat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moff_sex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moff_race\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moff_birth_year\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/uof_merge_filter1.ipynb#ch0000004?line=1'>2</a>\u001b[0m right_by \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mbeat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moff_sex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moff_race\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moff_year_of_birth\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/uof_merge_filter1.ipynb#ch0000004?line=3'>4</a>\u001b[0m missing_names[\u001b[39m\"\u001b[39m\u001b[39mdate_time\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(missing_names[\u001b[39m\"\u001b[39m\u001b[39mdate_time\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/uof_merge_filter1.ipynb#ch0000004?line=4'>5</a>\u001b[0m missing_names\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdate_time\u001b[39m\u001b[39m\"\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/uof_merge_filter1.ipynb#ch0000004?line=6'>7</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "left_by = [\"off_assigned_beat\", \"off_sex\", \"off_race\", \"off_birth_year\"]\n",
    "right_by = [\"beat\", \"off_sex\", \"off_race\", \"off_year_of_birth\"]\n",
    "\n",
    "missing_names[\"date_time\"] = pd.to_datetime(missing_names[\"date_time\"])\n",
    "missing_names.sort_values(by=\"date_time\", inplace=True)\n",
    "\n",
    "i = 0\n",
    "match_sets = []\n",
    "missing_names_remaining = missing_names\n",
    "missing_names_remaining.dropna(subset=[\"date_time\", \"off_birth_year\"], inplace=True)\n",
    "missing_names_remaining[\"off_birth_year\"] = missing_names[\"off_birth_year\"].astype(np.int64)\n",
    "\n",
    "with pd.read_csv(\"../files/events/officer_id_merged/assignments/assignments_full_merge.csv\", chunksize=10000) as reader:\n",
    "  for chunk in reader:\n",
    "    print(\"processing chunk\", i)\n",
    "    i += 1\n",
    "    chunk[\"off_race\"] = np.where(chunk[\"off_race\"].isna(), chunk[\"rdesc\"], chunk[\"off_race\"])\n",
    "    convert_race(chunk, [\"off_race\"])\n",
    "    chunk[\"shift_end_corrected\"] = pd.to_datetime(chunk[\"shift_end_corrected\"])\n",
    "    chunk.dropna(subset=[\"shift_end_corrected\", \"off_year_of_birth\"], inplace=True)\n",
    "    chunk.sort_values(by=\"shift_end_corrected\", inplace=True)\n",
    "    merged_chunk = pd.merge_asof(missing_names_remaining, chunk, left_on=\"date_time\", right_on=\"shift_end_corrected\", left_by=left_by, right_by=right_by, tolerance=pd.Timedelta(\"12 hours\"), suffixes=(\"\", \"_assignments\"))\n",
    "    match_sets.append(matches(merged_chunk, signifier=\"off_uniq_id\"))\n",
    "    missing_names_remaining = unmatched(merged_chunk, signifier=\"off_uniq_id\").loc[:, original_cols]\n",
    "\n",
    "matched_from_assignments = pd.concat(match_sets)\n",
    "matched_from_assignments[\"notes\"] = \"missing officer name; merged from assignments file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the join key []:\n",
      "\tNumber of records with more than one match: 63\n"
     ]
    }
   ],
   "source": [
    "dfs_to_concat = [successfully_merged, second_merge_successes, third_merge_matched, fourth_merge, matched_from_assignments, missing_names_remaining]\n",
    "full_merge_df = pd.concat(dfs_to_concat)\n",
    "ids_merged = full_merge_df[\"uof_id\"].to_numpy()\n",
    "m = ~original_uof_df.isin({\"uof_id\": ids_merged})\n",
    "missed_uof_entries = original_uof_df[m]\n",
    "full_merge_df = pd.concat([full_merge_df, missed_uof_entries])\n",
    "full_merge_df.sort_values(by=[\"date_time\", \"off_last_name\", \"off_first_name\"], inplace=True)\n",
    "full_merge_df.drop_duplicates(subset=[\"uof_id\", \"off_uniq_id\"], inplace=True)\n",
    "full_merge_df.reset_index(drop=True, inplace=True)\n",
    "full_merge_df.loc[:, out_cols].to_csv(out_file_path + \"/full_merge.csv\")\n",
    "full_merge_dupes = dupes(full_merge_df, \"uof_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22192    33146.0\n",
       "22193    33145.0\n",
       "23250    33146.0\n",
       "23251    33145.0\n",
       "27852    33146.0\n",
       "          ...   \n",
       "91126     1444.0\n",
       "91209    10624.0\n",
       "91210    10627.0\n",
       "91213      480.0\n",
       "91214      479.0\n",
       "Name: off_uniq_id, Length: 126, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_merge_df.groupby(\"uof_id\").size()\n",
    "# missing_names.shape[0]\n",
    "m = full_merge_df.isin({\"uof_id\": full_merge_dupes.reset_index()[\"uof_id\"].to_numpy()}).any(1)\n",
    "full_merge_df[m].loc[:, \"off_uniq_id\"]\n",
    "# full_merge_dupes.reset_index()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
