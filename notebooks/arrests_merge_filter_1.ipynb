{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4219/1472295026.py:7: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  arrests_df = pd.read_csv(\"../files/events/arrest_file.csv\", parse_dates=[\"date_time\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total arrest records 4853961\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cols = [\"date_time\", \"time\", \"date\", \"add_of_arrest\", \"officer_role\", \"off_first\", \"off_last\", \"off_star\", \"fbi_code\", \"statute\", \"civ_sex\", \"civ_race\", \"civ_age\", \"civ_first_name\", \"civ_last_name\"]\n",
    "\n",
    "out_file_path = \"../files/events/officer_id_merged/arrests/filter_1\"\n",
    "arrests_df = pd.read_csv(\"../files/events/arrest_file.csv\", parse_dates=[\"date_time\"])\n",
    "\n",
    "print(\"Total arrest records\", arrests_df.shape[0])\n",
    "\n",
    "\"\"\" Arrests are duplicated by fbi_code. Filter out the dupes \"\"\"\n",
    "group_key = [\"date_time\", \"time\", \"date\", \"add_of_arrest\", \"officer_role\", \"off_first\", \"off_last\", \"civ_sex\", \"civ_race\", \"civ_age\", \"civ_first_name\", \"civ_last_name\"]\n",
    "grouped_arrests_original = arrests_df.groupby(by=group_key, dropna=False).agg(\n",
    "  off_star=(\"off_star\", \"first\"),\n",
    "  fbi_codes=(\"fbi_code\", lambda codes: \",\".join(codes.unique())),\n",
    "  statutes=(\"statute\", lambda statutes: \",\".join(statutes.unique())),\n",
    "  charges= (\"fbi_code\", lambda codes: codes.unique().shape[0])\n",
    ")\n",
    "\n",
    "grouped_arrests_original = grouped_arrests_original.reset_index().sort_values(by=\"date_time\")\n",
    "grouped_arrests_original.to_csv(out_file_path + \"/arrests_deduped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrest records after being grouped by arresting officer 2682060\n",
      "Arrest records without an officer star 1324\n"
     ]
    }
   ],
   "source": [
    "print(\"Arrest records after being grouped by arresting officer\", grouped_arrests_original.shape[0])\n",
    "print(\"Arrest records without an officer star\", grouped_arrests_original[grouped_arrests_original[\"off_star\"].isna()].shape[0])\n",
    "grouped_arrests_original.index.name = \"arrest_id\"\n",
    "\n",
    "grouped_arrests_original = grouped_arrests_original.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of redacted arrest records 2735\n",
      "Number of un-redacted arrest records 2678001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4219/4153277104.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unredacted_arrests.loc[:, \"off_star\"] = pd.to_numeric(unredacted_arrests[\"off_star\"])\n"
     ]
    }
   ],
   "source": [
    "grouped_arrests_original[grouped_arrests_original[\"off_star\"].isna()].to_csv(out_file_path + \"/no_off_star.csv\", index=False)\n",
    "grouped_arrests = grouped_arrests_original.dropna(subset=[\"off_star\"])\n",
    "redacted_arrests = grouped_arrests[(grouped_arrests[\"off_first\"] == \"Redacted\") | (grouped_arrests[\"off_last\"] == \"Redacted\") | (grouped_arrests[\"off_star\"] == \"Redacted\")]\n",
    "redacted_arrests.to_csv(out_file_path + \"/redacted_arrests.csv\", index=False)\n",
    "redacted_arrest_ids = redacted_arrests[\"arrest_id\"].to_numpy()\n",
    "print(\"Number of redacted arrest records\", redacted_arrest_ids.size)\n",
    "unredacted_row_mask = ~grouped_arrests.isin({\"arrest_id\": redacted_arrest_ids}).any(1)\n",
    "unredacted_arrests = grouped_arrests[unredacted_row_mask]\n",
    "unredacted_arrests.to_csv(out_file_path + \"/unredacted_arrests.csv\", index=False)\n",
    "print(\"Number of un-redacted arrest records\", unredacted_arrests.shape[0])\n",
    "unredacted_arrests.loc[:, \"off_star\"] = pd.to_numeric(unredacted_arrests[\"off_star\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records merged by officer stars 2592163\n"
     ]
    }
   ],
   "source": [
    "\"\"\" @TODO just write the correct dtype to the roster file \"\"\"\n",
    "officer_roster = pd.read_csv(\"../files/profiles/officer_roster.csv\", dtype={\"off_star_0\": np.float64})\n",
    "\n",
    "left_on = [\"off_first\", \"off_last\", \"off_star\"]\n",
    "right_on = [\"off_first_name\", \"off_last_name\"]\n",
    "right_star_field_stub = \"off_star_\"\n",
    "\n",
    "star_merges = []\n",
    "out_cols = list(unredacted_arrests.columns.tolist()) + [\"merged_by_star\", \"off_uniq_id\"]\n",
    "\n",
    "for i in range(6):\n",
    "  off_star_field = right_star_field_stub + str(i)\n",
    "  star_merge = pd.merge(unredacted_arrests, officer_roster, left_on=left_on, right_on=right_on + [off_star_field], how=\"left\")\n",
    "  # drop unmatched records. But we need to merge them back in eventually\n",
    "  star_merge.dropna(subset=\"off_uniq_id\", inplace=True)\n",
    "  star_merge.to_csv(out_file_path + \"/star_{}_merge.csv\".format(i))\n",
    "  star_merge.loc[:, \"merged_by_star\"] = i\n",
    "  star_merges.append(star_merge.loc[:, out_cols])\n",
    "\n",
    "full_star_merge = pd.concat(star_merges, ignore_index=True)\n",
    "full_star_merge.sort_values(by=\"arrest_id\", inplace=True, ignore_index=True)\n",
    "print(\"Number of records merged by officer stars\", full_star_merge.shape[0])\n",
    "\n",
    "full_star_merge.to_csv(out_file_path + \"/matched_by_off_star.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = full_star_merge.groupby(\"arrest_id\").size().sort_values(ascending=False).to_frame(\"size\")\n",
    "ids_with_multiple_matches = grouped[grouped[\"size\"] > 1].index.to_numpy()\n",
    "row_mask = full_star_merge.isin({\"arrest_id\": ids_with_multiple_matches}).any(1)\n",
    "multiple_matches = full_star_merge[row_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_matches.to_csv(out_file_path + \"/matched_to_multiple_officers.csv\", index=False)\n",
    "\n",
    "single_matches = full_star_merge[~row_mask]\n",
    "single_matches.to_csv(out_file_path + \"/matched_to_single_officer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing chunk 0\n",
      "Based on the join key []:\n",
      "\tNumber of matches: 2\n",
      "Based on the join key []:\n",
      "\tNumber of unmatched records: 26513\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/kroy/proj/policing/cpd-parse/notebooks/arrests_merge_filter_1.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/arrests_merge_filter_1.ipynb#ch0000006?line=27'>28</a>\u001b[0m     \u001b[39m# merged_chunk = pd.merge(duplicates_remaining, chunk, on=[\"off_uniq_id\", \"off_star\"], suffixes=(\"\", \"_assignments\"), how=\"left\").drop_duplicates(subset=[\"arrest_id\", \"off_uniq_id\"])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/arrests_merge_filter_1.ipynb#ch0000006?line=28'>29</a>\u001b[0m     confirmed_match_dfs\u001b[39m.\u001b[39mappend(matches(merged_chunk, signifier\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moff_appointed\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/arrests_merge_filter_1.ipynb#ch0000006?line=29'>30</a>\u001b[0m     duplicates_remaining \u001b[39m=\u001b[39m unmatched(merged_chunk, signifier\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moff_appointed\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mloc[:, original_cols]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/arrests_merge_filter_1.ipynb#ch0000006?line=31'>32</a>\u001b[0m confirmed_matches \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(confirmed_match_dfs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kroy/proj/policing/cpd-parse/notebooks/arrests_merge_filter_1.ipynb#ch0000006?line=32'>33</a>\u001b[0m confirmed_match_dupes \u001b[39m=\u001b[39m dupes(confirmed_matches, signifier\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marrest_id\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=958'>959</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=959'>960</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=960'>961</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=961'>962</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=962'>963</a>\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1145'>1146</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1146'>1147</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1148'>1149</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=823'>824</a>\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=824'>825</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=826'>827</a>\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=827'>828</a>\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=828'>829</a>\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=829'>830</a>\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1187'>1188</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1188'>1189</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1190'>1191</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1192'>1193</a>\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1193'>1194</a>\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1128'>1129</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1130'>1131</a>\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1131'>1132</a>\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1132'>1133</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1133'>1134</a>\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1134'>1135</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1323'>1324</a>\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1324'>1325</a>\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1326'>1327</a>\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexing.py?line=1328'>1329</a>\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5778'>5779</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5779'>5780</a>\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5781'>5782</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5783'>5784</a>\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5784'>5785</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5785'>5786</a>\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5841'>5842</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5843'>5844</a>\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> <a href='file:///home/kroy/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5844'>5845</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['date'] not in index\""
     ]
    }
   ],
   "source": [
    "from metrics.analyze_df import matches, unmatched, dupes\n",
    "import numpy as np\n",
    "\n",
    "duplicates_remaining = multiple_matches\n",
    "duplicates_remaining[\"date_time\"] = pd.to_datetime(duplicates_remaining[\"date_time\"])\n",
    "duplicates_remaining[\"off_uniq_id\"] = duplicates_remaining.loc[:, \"off_uniq_id\"].astype(np.int64)\n",
    "duplicates_remaining = duplicates_remaining.sort_values(by=\"date_time\")\n",
    "original_cols = duplicates_remaining.columns\n",
    "confirmed_match_dfs = []\n",
    "i = 0\n",
    "\n",
    "with pd.read_csv(\"../files/events/officer_id_merged/assignments/assignments_full_merge.csv\", chunksize=10000) as reader:\n",
    "  for chunk in reader:\n",
    "    \"\"\"\n",
    "      In the arrests file, we have officer last, first, and star. \n",
    "      With this limited matching criteria, we have a number of duplicate matches that\n",
    "      we can attempt to weed out using the assignment file. The idea is that given\n",
    "      an arrest matched with both off_uniq_id_a and off_uniq_id_b, we attempt to\n",
    "      find an assignment record corresponding to that officer by off_uniq_id and off_star.\n",
    "      If we can't find a record of a given officer in the assignments file, then we\n",
    "      ignore that match\n",
    "    \"\"\"\n",
    "    print(\"processing chunk\", i)\n",
    "    i += 1\n",
    "    chunk.dropna(subset=[\"shift_start\"], inplace=True)\n",
    "    chunk[\"shift_start\"] = pd.to_datetime(chunk[\"shift_start\"], format=\"%Y-%m-%d %H:%M:%S\", utc=True)\n",
    "    chunk.sort_values(by=\"shift_start\", inplace=True)\n",
    "    merged_chunk = pd.merge_asof(duplicates_remaining, chunk, left_on=[\"date_time\"], right_on=[\"shift_start\"], by=[\"off_uniq_id\", \"off_star\"], tolerance=pd.Timedelta(\"24 hours\"))\n",
    "    # merged_chunk = pd.merge(duplicates_remaining, chunk, on=[\"off_uniq_id\", \"off_star\"], suffixes=(\"\", \"_assignments\"), how=\"left\").drop_duplicates(subset=[\"arrest_id\", \"off_uniq_id\"])\n",
    "    confirmed_match_dfs.append(matches(merged_chunk, signifier=\"off_appointed\"))\n",
    "    duplicates_remaining = unmatched(merged_chunk, signifier=\"off_appointed\").loc[:, original_cols]\n",
    "\n",
    "confirmed_matches = pd.concat(confirmed_match_dfs)\n",
    "confirmed_match_dupes = dupes(confirmed_matches, signifier=\"arrest_id\")\n",
    "confirmed_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrest_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>add_of_arrest</th>\n",
       "      <th>officer_role</th>\n",
       "      <th>off_first</th>\n",
       "      <th>off_last</th>\n",
       "      <th>civ_sex</th>\n",
       "      <th>civ_race</th>\n",
       "      <th>civ_age</th>\n",
       "      <th>civ_first_name</th>\n",
       "      <th>civ_last_name</th>\n",
       "      <th>off_star</th>\n",
       "      <th>fbi_codes</th>\n",
       "      <th>statutes</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>2014-01-01 00:05:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>31XX W WALNUT ST</td>\n",
       "      <td>Second Arresting Officer</td>\n",
       "      <td>CLIFFORD</td>\n",
       "      <td>HALL</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>61.0</td>\n",
       "      <td>ARTHUR</td>\n",
       "      <td>ROBERTS</td>\n",
       "      <td>12115</td>\n",
       "      <td>15</td>\n",
       "      <td>720 ILCS 5.0/24-1.5-A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>2014-01-01 00:05:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>31XX W WALNUT ST</td>\n",
       "      <td>First Arresting Officer</td>\n",
       "      <td>MARIO</td>\n",
       "      <td>CRUZ</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>61.0</td>\n",
       "      <td>ARTHUR</td>\n",
       "      <td>ROBERTS</td>\n",
       "      <td>16659</td>\n",
       "      <td>15</td>\n",
       "      <td>720 ILCS 5.0/24-1.5-A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>86</td>\n",
       "      <td>2014-01-01 00:10:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>52XX S INDIANA AVE</td>\n",
       "      <td>Second Arresting Officer</td>\n",
       "      <td>FRANK</td>\n",
       "      <td>RAMAGLIA</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>26.0</td>\n",
       "      <td>RODNEY</td>\n",
       "      <td>HILL</td>\n",
       "      <td>1775</td>\n",
       "      <td>15</td>\n",
       "      <td>720 ILCS 5.0/24-1.1-A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>111</td>\n",
       "      <td>2014-01-01 00:10:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>64XX S WHIPPLE ST</td>\n",
       "      <td>Second Arresting Officer</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>GALLAS</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>27.0</td>\n",
       "      <td>JESSICA</td>\n",
       "      <td>JUAREZ</td>\n",
       "      <td>17815</td>\n",
       "      <td>26</td>\n",
       "      <td>720 ILCS 5.0/31-1-A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>112</td>\n",
       "      <td>2014-01-01 00:10:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>64XX S WHIPPLE ST</td>\n",
       "      <td>Second Arresting Officer</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>GALLAS</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>21.0</td>\n",
       "      <td>JAMIE</td>\n",
       "      <td>OROZCO</td>\n",
       "      <td>17815</td>\n",
       "      <td>15</td>\n",
       "      <td>720 ILCS 5.0/24-1.5-A,720 ILCS 5.0/24-1.6-A-2,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681832</th>\n",
       "      <td>2681832</td>\n",
       "      <td>2021-08-18 16:40:00+00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>62XX W NORTH AVE</td>\n",
       "      <td>First Arresting Officer</td>\n",
       "      <td>PIERRE</td>\n",
       "      <td>PARGO</td>\n",
       "      <td>MALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>27.0</td>\n",
       "      <td>TYRON</td>\n",
       "      <td>BROOKS</td>\n",
       "      <td>15096.0</td>\n",
       "      <td>15,WRT</td>\n",
       "      <td>720 ILCS 5.0/24-1.1-A,725 ILCS 5.0/110-3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681871</th>\n",
       "      <td>2681873</td>\n",
       "      <td>2021-08-18 23:00:00+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-08-18</td>\n",
       "      <td>49XX W MADISON ST</td>\n",
       "      <td>First Arresting Officer</td>\n",
       "      <td>NICHOLAS</td>\n",
       "      <td>CARTER</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>29.0</td>\n",
       "      <td>BESSIE</td>\n",
       "      <td>CONNERS</td>\n",
       "      <td>15536.0</td>\n",
       "      <td>26</td>\n",
       "      <td>720 ILCS 5.0/21-3-A-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681949</th>\n",
       "      <td>2681949</td>\n",
       "      <td>2021-08-19 10:40:00+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>51XX N MILWAUKEE AVE</td>\n",
       "      <td>Second Arresting Officer</td>\n",
       "      <td>ANGELA</td>\n",
       "      <td>OLIFER</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>48.0</td>\n",
       "      <td>RENATA</td>\n",
       "      <td>FLIG</td>\n",
       "      <td>13640</td>\n",
       "      <td>26</td>\n",
       "      <td>510 ILCS 70.0/3.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681960</th>\n",
       "      <td>2681960</td>\n",
       "      <td>2021-08-19 11:47:00+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>28XX W IRVING PARK RD</td>\n",
       "      <td>Assisting Arresting Officer</td>\n",
       "      <td>NIKI</td>\n",
       "      <td>TEWS</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>61.0</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>HIGHAM</td>\n",
       "      <td>1543.0</td>\n",
       "      <td>26,08A</td>\n",
       "      <td>720 ILCS 5.0/21-3-A-2,720 ILCS 5.0/12-1-A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681970</th>\n",
       "      <td>2681970</td>\n",
       "      <td>2021-08-19 13:02:00+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2021-08-19</td>\n",
       "      <td>92XX S SAGINAW AVE</td>\n",
       "      <td>Second Arresting Officer</td>\n",
       "      <td>NICHYRIA</td>\n",
       "      <td>BYRD</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ALEJANDRO</td>\n",
       "      <td>CAJERO</td>\n",
       "      <td>15481.0</td>\n",
       "      <td>08B</td>\n",
       "      <td>720 ILCS 5.0/12-3.2-A-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103388 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arrest_id  ... charges\n",
       "21              23  ...       1\n",
       "27              22  ...       1\n",
       "56              86  ...       1\n",
       "79             111  ...       1\n",
       "80             112  ...       1\n",
       "...            ...  ...     ...\n",
       "2681832    2681832  ...       2\n",
       "2681871    2681873  ...       1\n",
       "2681949    2681949  ...       1\n",
       "2681960    2681960  ...       2\n",
       "2681970    2681970  ...       1\n",
       "\n",
       "[103388 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_arrest_ids = full_star_merge[\"arrest_id\"].to_numpy()\n",
    "rmask = ~grouped_arrests_original.isin({\"arrest_id\": matched_arrest_ids}).any(1)\n",
    "missing_arrests = grouped_arrests_original[rmask]\n",
    "missing_arrests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrest_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>add_of_arrest</th>\n",
       "      <th>officer_role</th>\n",
       "      <th>off_first</th>\n",
       "      <th>off_last</th>\n",
       "      <th>civ_sex</th>\n",
       "      <th>civ_race</th>\n",
       "      <th>civ_age</th>\n",
       "      <th>civ_first_name</th>\n",
       "      <th>civ_last_name</th>\n",
       "      <th>off_star</th>\n",
       "      <th>fbi_codes</th>\n",
       "      <th>statutes</th>\n",
       "      <th>charges</th>\n",
       "      <th>merged_by_star</th>\n",
       "      <th>off_uniq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [arrest_id, date_time, time, date, add_of_arrest, officer_role, off_first, off_last, civ_sex, civ_race, civ_age, civ_first_name, civ_last_name, off_star, fbi_codes, statutes, charges, merged_by_star, off_uniq_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmed_arrest_ids = confirmed_matches.loc[:, \"arrest_id\"].to_numpy()\n",
    "rmask = ~duplicates_remaining.isin({\"arrest_id\": confirmed_arrest_ids}).any(1)\n",
    "duplicates_remaining[rmask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arrest_id\n",
       "974122     2\n",
       "2627262    2\n",
       "1542446    2\n",
       "8657       2\n",
       "2585188    2\n",
       "          ..\n",
       "894069     1\n",
       "894070     1\n",
       "894071     1\n",
       "894072     1\n",
       "2682059    1\n",
       "Length: 2682060, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_arrests = pd.concat([single_matches, confirmed_matches, missing_arrests], ignore_index=True).loc[:, out_cols].sort_values(by=\"arrest_id\", ignore_index=True)\n",
    "all_arrests.drop_duplicates(subset=[\"arrest_id\", \"off_uniq_id\"]).groupby(\"arrest_id\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right_on = [\"off_first_name\", \"off_last_name\", \"off_star_2\"]\n",
    "# star_2_merge = pd.merge(unmatched_star_1, officer_roster, left_on=left_on, right_on=right_on, how=\"left\")\n",
    "# star_2_merge[star_2_merge[\"off_uniq_id\"].isna()]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
