{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/xh9hskwj4q9bvjqcy131pv9c0000gn/T/ipykernel_79813/1571582512.py:7: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stops_df = pd.read_csv(base_file_path + \"/events/stops_by_fo_birth_year.csv\", index_col=\"stop_id\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of profiles: 36504\n",
      "number of profiles with a birth year: 36502\n",
      "number of stops: 2865566\n",
      "number of stops with a birth year: 2854561\n",
      "number of stops after dropping empty keys 2854561\n",
      "number of officers after dropping empty keys 36502\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data_tweak.converters import convert_race, convert_sex\n",
    "base_file_path = \"../files\"\n",
    "out_file_path = base_file_path + \"/events/officer_id_merged/stops/filter_v3\"\n",
    "\n",
    "officer_prof_df = pd.read_csv(base_file_path + \"/profiles/officers_index_step_4.csv\")\n",
    "stops_df = pd.read_csv(base_file_path + \"/events/stops_by_fo_birth_year.csv\", index_col=\"stop_id\")\n",
    "stops_df.reset_index(inplace=True)\n",
    "\n",
    "print(\"number of profiles:\", officer_prof_df.shape[0])\n",
    "officer_prof_df = officer_prof_df.dropna(subset=[\"off_year_of_birth\"]).sort_values(\"off_year_of_birth\")\n",
    "print(\"number of profiles with a birth year:\", officer_prof_df.shape[0])\n",
    "print(\"number of stops:\", stops_df.shape[0])\n",
    "\n",
    "join_left_cols = [\"first_off_first_name\", \"first_off_last_name\", \"first_off_sex\", \"first_off_race\"]\n",
    "join_right_cols = [\"off_first_name\", \"off_last_name\", \"off_sex\", \"off_race\"]\n",
    "age_cols = [\"first_off_age\", \"first_off_latest_birth_year\"]\n",
    "\n",
    "stops_df[stops_df[join_left_cols].isna().any(axis=1)].to_csv(out_file_path + \"/first_off_key_missing.csv\", index=False)\n",
    "\n",
    "stops_df.dropna(axis=\"index\", how=\"all\", subset=join_left_cols, inplace=True)\n",
    "stops_df.dropna(axis=\"index\", how=\"any\", subset=age_cols, inplace=True)\n",
    "print(\"number of stops with a birth year:\", stops_df.shape[0])\n",
    "officer_prof_df.dropna(axis=\"index\", how=\"all\", subset=join_right_cols, inplace=True)\n",
    "officer_prof_df.dropna(axis=\"index\", how=\"any\", subset=[\"off_year_of_birth\"], inplace=True)\n",
    "\n",
    "print(\"number of stops after dropping empty keys\", stops_df.shape[0])\n",
    "print(\"number of officers after dropping empty keys\", officer_prof_df.shape[0])\n",
    "\n",
    "convert_sex(stops_df, [\"first_off_sex\", \"second_off_sex\"])\n",
    "convert_race(stops_df, [\"first_off_race\", \"second_off_race\"])\n",
    "\n",
    "# Just do in the profile generation\n",
    "convert_sex(officer_prof_df, [\"off_sex\"])\n",
    "convert_race(officer_prof_df, [\"off_race\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial merge rows 2854561\n",
      "rows with an uid for the first officer 2853653\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_cols = list(stops_df.columns.values.tolist()) + [\"off_uniq_id\"]\n",
    "stops_merged_df = pd.merge_asof(stops_df, officer_prof_df, left_on=[\"first_off_latest_birth_year\"], right_on=[\"off_year_of_birth\"], left_by=join_left_cols, right_by=join_right_cols, tolerance=1)\n",
    "stops_merged_df.loc[:, out_cols].to_csv(out_file_path + \"/half_merged.csv\", index=False)\n",
    "print(\"initial merge rows\", stops_merged_df.shape[0])\n",
    "print(\"rows with an uid for the first officer\", stops_merged_df[stops_merged_df[\"off_uniq_id\"].notna()].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_left_cols = [\"second_off_first_name\", \"second_off_last_name\", \"second_off_sex\", \"second_off_race\"]\n",
    "age_cols = [\"second_off_age\", \"second_off_latest_birth_year\"]\n",
    "\"\"\" @TODO output rejected second off rows \"\"\"\n",
    "stops_merged_df[stops_merged_df[join_left_cols + age_cols].isna().any(axis=1)].to_csv(out_file_path + \"/second_off_key_missing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing stops with a second officer 2464906\n",
      "number of stops matched with a second officer 2463846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "second_off_stops = stops_merged_df.sort_values(\"second_off_latest_birth_year\").dropna(subset=join_left_cols, how=\"any\")\n",
    "print(\"processing stops with a second officer\", second_off_stops.shape[0])\n",
    "second_off_stops_merged = pd.merge_asof(second_off_stops, officer_prof_df, left_on=[\"second_off_latest_birth_year\"], right_on=[\"off_year_of_birth\"], left_by=join_left_cols, right_by=join_right_cols, suffixes=(\"\", \"_second_off\"), tolerance=1)\n",
    "out_cols = list(stops_df.columns.values.tolist()) + [\"off_uniq_id\", \"off_uniq_id_second_off\"]\n",
    "second_off_stops_merged.loc[:, out_cols].to_csv(out_file_path + \"/second_off_stops_merged.csv\", index=False)\n",
    "print(\"number of stops matched with a second officer\", second_off_stops_merged[second_off_stops_merged[\"off_uniq_id_second_off\"].notna()].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the full merge 2854561\n",
      "Total number of rows missing a UID for the first officer 908\n",
      "Total number of rows missing a UID for the second officer 5113\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Consider, this chooses the closest match looking backwards in terms of birth date. Is this what we want? \"\"\"\n",
    "\n",
    "full_merge = pd.concat([second_off_stops_merged, stops_merged_df])\n",
    "full_merge = full_merge.drop_duplicates(subset=[\"stop_id\"])\n",
    "full_merge.loc[:, out_cols].to_csv(out_file_path + \"/full_merge.csv\", index=False)\n",
    "print(\"Total number of rows in the full merge\", full_merge.shape[0])\n",
    "print(\"Total number of rows missing a UID for the first officer\", full_merge[full_merge[\"off_uniq_id\"].isna()].shape[0])\n",
    "missing_fo = full_merge[full_merge[\"off_uniq_id\"].isna()]\n",
    "missing_fo.to_csv(out_file_path + \"/missing_fo_id.csv\", index=False)\n",
    "print(\"Total number of rows missing a UID for the second officer\", full_merge[full_merge[\"second_off_first_name\"].notna() & full_merge[\"off_uniq_id_second_off\"].isna()].shape[0])\n",
    "missing_so = full_merge[full_merge[\"second_off_first_name\"].notna() & full_merge[\"off_uniq_id_second_off\"].isna()]\n",
    "missing_so.to_csv(out_file_path + \"/missing_so_id.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows missing a UID for just the second officer 5113\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of rows missing a UID for just the second officer\", full_merge[full_merge[\"off_uniq_id\"].notna() & full_merge[\"second_off_first_name\"].notna() & full_merge[\"off_uniq_id_second_off\"].isna()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/xh9hskwj4q9bvjqcy131pv9c0000gn/T/ipykernel_79813/3405568228.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_fo.sort_values(by=\"first_off_latest_birth_year\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>stop_address</th>\n",
       "      <th>district</th>\n",
       "      <th>beat</th>\n",
       "      <th>contact_type</th>\n",
       "      <th>first_off_last_name</th>\n",
       "      <th>first_off_first_name</th>\n",
       "      <th>first_off_sex</th>\n",
       "      <th>first_off_race</th>\n",
       "      <th>...</th>\n",
       "      <th>off_appointed_y</th>\n",
       "      <th>off_race_y</th>\n",
       "      <th>ranks_held_y</th>\n",
       "      <th>off_star_0_y</th>\n",
       "      <th>off_star_1_y</th>\n",
       "      <th>off_star_2_y</th>\n",
       "      <th>off_star_3_y</th>\n",
       "      <th>off_star_4_y</th>\n",
       "      <th>off_star_5_y</th>\n",
       "      <th>off_source_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>477358</td>\n",
       "      <td>2012-12-01 22:54:00+00:00</td>\n",
       "      <td>28XX DIVISION ST</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>Suspicious Person</td>\n",
       "      <td>CHRIS</td>\n",
       "      <td>SYSTEM</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1108808</td>\n",
       "      <td>2013-09-29 10:57:00+00:00</td>\n",
       "      <td>41XX MICHIGAN AVE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>BRADLEY</td>\n",
       "      <td>VALENA</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1989-12-26</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>17810.0</td>\n",
       "      <td>10029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464193</td>\n",
       "      <td>2012-11-22 11:05:00+00:00</td>\n",
       "      <td>38XX CALUMET AVE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>BRADLEY</td>\n",
       "      <td>VALENA</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1989-12-26</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>17810.0</td>\n",
       "      <td>10029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62975</td>\n",
       "      <td>2012-02-18 12:27:00+00:00</td>\n",
       "      <td>2XX 35TH ST</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>Traffic Related</td>\n",
       "      <td>BRADLEY</td>\n",
       "      <td>VALENA</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1989-12-26</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>17810.0</td>\n",
       "      <td>10029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39650</td>\n",
       "      <td>2012-02-01 14:45:00+00:00</td>\n",
       "      <td>35XX GILES AVE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>Traffic Related</td>\n",
       "      <td>BRADLEY</td>\n",
       "      <td>VALENA</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1989-12-26</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>17810.0</td>\n",
       "      <td>10029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>1239909</td>\n",
       "      <td>2014-03-11 17:25:00+00:00</td>\n",
       "      <td>90XX ASHLAND AVE</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>Gang / Narcotics Related</td>\n",
       "      <td>ALVARADO</td>\n",
       "      <td>MATTHEW</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>...</td>\n",
       "      <td>2006-11-27</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>POLICE OFFICER ASSIGNED AS FIELD TRAINING OFFICER</td>\n",
       "      <td>10456.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>2757426</td>\n",
       "      <td>2019-10-31 21:43:00+00:00</td>\n",
       "      <td>52XX IRVING PARK RD</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>INVSTG</td>\n",
       "      <td>MATTHEWS</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2863711</td>\n",
       "      <td>2020-12-19 22:35:00+00:00</td>\n",
       "      <td>38XX DIVISION ST</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>INVSTG</td>\n",
       "      <td>MATTHEWS</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2776344</td>\n",
       "      <td>2019-12-22 01:00:00+00:00</td>\n",
       "      <td>21XX LARAMIE AVE</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2522.0</td>\n",
       "      <td>INVSTG</td>\n",
       "      <td>MATTHEWS</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>2863710</td>\n",
       "      <td>2020-12-19 22:35:00+00:00</td>\n",
       "      <td>38XX DIVISION ST</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>INVSTG</td>\n",
       "      <td>MATTHEWS</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>assignments_file</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stop_id                  date_time         stop_address  district  \\\n",
       "0     477358  2012-12-01 22:54:00+00:00     28XX DIVISION ST      13.0   \n",
       "1    1108808  2013-09-29 10:57:00+00:00    41XX MICHIGAN AVE       2.0   \n",
       "2     464193  2012-11-22 11:05:00+00:00     38XX CALUMET AVE       2.0   \n",
       "3      62975  2012-02-18 12:27:00+00:00          2XX 35TH ST      21.0   \n",
       "4      39650  2012-02-01 14:45:00+00:00       35XX GILES AVE       2.0   \n",
       "..       ...                        ...                  ...       ...   \n",
       "903  1239909  2014-03-11 17:25:00+00:00     90XX ASHLAND AVE      22.0   \n",
       "904  2757426  2019-10-31 21:43:00+00:00  52XX IRVING PARK RD      16.0   \n",
       "905  2863711  2020-12-19 22:35:00+00:00     38XX DIVISION ST      11.0   \n",
       "906  2776344  2019-12-22 01:00:00+00:00     21XX LARAMIE AVE      25.0   \n",
       "907  2863710  2020-12-19 22:35:00+00:00     38XX DIVISION ST      11.0   \n",
       "\n",
       "       beat              contact_type first_off_last_name  \\\n",
       "0    1311.0         Suspicious Person               CHRIS   \n",
       "1     213.0                     Other             BRADLEY   \n",
       "2     212.0                     Other             BRADLEY   \n",
       "3    2112.0           Traffic Related             BRADLEY   \n",
       "4     211.0           Traffic Related             BRADLEY   \n",
       "..      ...                       ...                 ...   \n",
       "903  2221.0  Gang / Narcotics Related            ALVARADO   \n",
       "904  1634.0                    INVSTG            MATTHEWS   \n",
       "905  1112.0                    INVSTG            MATTHEWS   \n",
       "906  2522.0                    INVSTG            MATTHEWS   \n",
       "907  1112.0                    INVSTG            MATTHEWS   \n",
       "\n",
       "    first_off_first_name first_off_sex first_off_race  ...  off_appointed_y  \\\n",
       "0                 SYSTEM            NA            NaN  ...              NaN   \n",
       "1                 VALENA        FEMALE            NaN  ...       1989-12-26   \n",
       "2                 VALENA        FEMALE            NaN  ...       1989-12-26   \n",
       "3                 VALENA        FEMALE            NaN  ...       1989-12-26   \n",
       "4                 VALENA        FEMALE            NaN  ...       1989-12-26   \n",
       "..                   ...           ...            ...  ...              ...   \n",
       "903              MATTHEW          MALE          WHITE  ...       2006-11-27   \n",
       "904                DAVID          MALE            NaN  ...       2019-02-19   \n",
       "905                DAVID          MALE            NaN  ...       2019-02-19   \n",
       "906                DAVID          MALE            NaN  ...       2019-02-19   \n",
       "907                DAVID          MALE            NaN  ...       2019-02-19   \n",
       "\n",
       "    off_race_y                                       ranks_held_y  \\\n",
       "0          NaN                                                NaN   \n",
       "1        BLACK                                     POLICE OFFICER   \n",
       "2        BLACK                                     POLICE OFFICER   \n",
       "3        BLACK                                     POLICE OFFICER   \n",
       "4        BLACK                                     POLICE OFFICER   \n",
       "..         ...                                                ...   \n",
       "903   HISPANIC  POLICE OFFICER ASSIGNED AS FIELD TRAINING OFFICER   \n",
       "904   HISPANIC                                     POLICE OFFICER   \n",
       "905   HISPANIC                                     POLICE OFFICER   \n",
       "906   HISPANIC                                     POLICE OFFICER   \n",
       "907   HISPANIC                                     POLICE OFFICER   \n",
       "\n",
       "    off_star_0_y off_star_1_y  off_star_2_y off_star_3_y off_star_4_y  \\\n",
       "0            NaN          NaN           NaN          NaN          NaN   \n",
       "1        17810.0      10029.0           NaN          NaN          NaN   \n",
       "2        17810.0      10029.0           NaN          NaN          NaN   \n",
       "3        17810.0      10029.0           NaN          NaN          NaN   \n",
       "4        17810.0      10029.0           NaN          NaN          NaN   \n",
       "..           ...          ...           ...          ...          ...   \n",
       "903      10456.0          NaN           NaN          NaN          NaN   \n",
       "904      18030.0          NaN           NaN          NaN          NaN   \n",
       "905      18030.0          NaN           NaN          NaN          NaN   \n",
       "906      18030.0          NaN           NaN          NaN          NaN   \n",
       "907      18030.0          NaN           NaN          NaN          NaN   \n",
       "\n",
       "     off_star_5_y      off_source_y  \n",
       "0             NaN               NaN  \n",
       "1             NaN  assignments_file  \n",
       "2             NaN  assignments_file  \n",
       "3             NaN  assignments_file  \n",
       "4             NaN  assignments_file  \n",
       "..            ...               ...  \n",
       "903           NaN  assignments_file  \n",
       "904           NaN  assignments_file  \n",
       "905           NaN  assignments_file  \n",
       "906           NaN  assignments_file  \n",
       "907           NaN  assignments_file  \n",
       "\n",
       "[908 rows x 77 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" attempt to match without race \"\"\"\n",
    "\n",
    "join_left_cols = [\"first_off_first_name\", \"first_off_last_name\", \"first_off_sex\"]\n",
    "join_right_cols = [\"off_first_name\", \"off_last_name\", \"off_sex\"]\n",
    "missing_fo.sort_values(by=\"first_off_latest_birth_year\", inplace=True)\n",
    "\n",
    "merged_without_race = pd.merge_asof(missing_fo, officer_prof_df, left_on=[\"first_off_latest_birth_year\"], right_on=[\"off_year_of_birth\"], left_by=join_left_cols, right_by=join_right_cols, tolerance=1)\n",
    "merged_without_race"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
