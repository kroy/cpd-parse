{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23142/1362968511.py:7: DtypeWarning: Columns (3,5,6,7,8,10,11,12,13,20,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  stops_df = pd.read_csv(base_file_path + \"/events/stops_full.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops to be processed:  2865566\n",
      "initial merge rows 2524993\n",
      "full_merge rows 2827393\n",
      "number of rows w/ a 2nd off 2514988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data_tweak.converters import convert_race, convert_sex\n",
    "base_file_path = \"../files\"\n",
    "out_file_path = base_file_path + \"/events/officer_id_merged/stops/filter_1/kiefer\"\n",
    "\n",
    "officer_prof_df = pd.read_csv(base_file_path + \"/profiles/officers_index_plus_kiefer.csv\")\n",
    "stops_df = pd.read_csv(base_file_path + \"/events/stops_full.csv\")\n",
    "stops_df.index.name = \"stops_index\"\n",
    "stops_df.reset_index(inplace=True)\n",
    "\n",
    "print(\"Number of stops to be processed: \", stops_df.shape[0])\n",
    "\n",
    "join_left_cols = [\"first_off_first_name\", \"first_off_last_name\", \"first_off_sex\", \"first_off_race\"]\n",
    "join_right_cols = [\"off_first_name\", \"off_last_name\", \"off_sex\", \"off_race\"]\n",
    "\n",
    "stops_df.dropna(axis=\"index\", how=\"any\", subset=join_left_cols, inplace=True)\n",
    "officer_prof_df.dropna(axis=\"index\", how=\"any\", subset=join_right_cols, inplace=True)\n",
    "\n",
    "convert_sex(stops_df, [\"first_off_sex\", \"second_off_sex\"])\n",
    "convert_race(stops_df, [\"first_off_race\", \"second_off_race\"])\n",
    "\n",
    "# Just do in the profile generation\n",
    "convert_sex(officer_prof_df, [\"off_sex\"])\n",
    "convert_race(officer_prof_df, [\"off_race\"])\n",
    "\n",
    "out_cols = list(stops_df.columns.values.tolist()) + [\"off_uniq_id\"]\n",
    "stops_merged_df = pd.merge(stops_df, officer_prof_df, how=\"left\", left_on=join_left_cols, right_on=join_right_cols, suffixes=(\"_stop\", \"_first_off\"), validate=\"m:m\")\n",
    "stops_merged_df.loc[:, out_cols].to_csv(out_file_path + \"/half_merged.csv\", index=False)\n",
    "print(\"initial merge rows\", stops_merged_df.shape[0])\n",
    "join_left_cols = [\"second_off_first_name\", \"second_off_last_name\", \"second_off_sex\", \"second_off_race\"]\n",
    "# second_off_stops = stops_merged_df.dropna(axis=\"index\", how=\"any\", subset=join_left_cols)\n",
    "full_merge = pd.merge(stops_merged_df, officer_prof_df, how=\"left\", left_on=join_left_cols, right_on=join_right_cols, suffixes=(\"\", \"_second_off\"), validate=\"m:m\")\n",
    "# full_merge = pd.merge(stops_merged_df, second_off_stops_merged_df, how=\"left\")\n",
    "out_cols = out_cols + [\"off_uniq_id_second_off\"]\n",
    "full_merge.loc[:, out_cols].to_csv(out_file_path + \"/full_merge_attempt.csv\", index=False)\n",
    "print(\"full_merge rows\", full_merge.shape[0])\n",
    "full_merge[full_merge[\"off_uniq_id\"].isna()].loc[:, out_cols].to_csv(out_file_path + \"/missing_1st_off.csv\", index=False)\n",
    "print(\"number of rows w/ a 2nd off\", full_merge[full_merge[\"second_off_first_name\"].notna()].shape[0])\n",
    "full_merge[full_merge[\"second_off_first_name\"].notna() & full_merge[\"off_uniq_id_second_off\"].isna()].loc[:, out_cols].to_csv(out_file_path + \"/missing_2nd_off.csv\", index=False)\n",
    "matches_by_stops_index = full_merge.groupby(\"stops_index\").size().reset_index(name=\"count\")\n",
    "stops_index_multiple = matches_by_stops_index[matches_by_stops_index[\"count\"] > 1][\"stops_index\"].to_numpy()\n",
    "row_mask = full_merge.isin({'stops_index': stops_index_multiple}).any(1)\n",
    "full_merge[row_mask].loc[:, out_cols].to_csv(out_file_path + \"/multiple_matches.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-to-1 matches found: 1805218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Take out missing matches, and duplicate matches so we have a decent set of data \"\"\"\n",
    "stops_index_single = matches_by_stops_index[matches_by_stops_index[\"count\"] == 1][\"stops_index\"].to_numpy()\n",
    "row_mask = full_merge.isin({'stops_index': stops_index_single}).any(1)\n",
    "only_matches = full_merge[row_mask]\n",
    "only_matches = only_matches[only_matches[\"off_uniq_id\"].notna()]\n",
    "\n",
    "only_matches = only_matches[(only_matches[\"second_off_first_name\"].isna()) | (only_matches[\"second_off_first_name\"].notna() & only_matches[\"off_uniq_id_second_off\"].notna())]\n",
    "print(\"1-to-1 matches found:\", only_matches.shape[0])\n",
    "only_matches.loc[:, out_cols].to_csv(base_file_path + \"/events/officer_id_merged/stops/filter_1/kiefer/1_to_1_merges.csv\")\n",
    "\n",
    "# full_merge[full_merge.duplicated(subset=[\"stops_index\"])].to_csv(base_file_path + \"/events/officer_id_merged/stops_merged_filter_1_multiple_match.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
